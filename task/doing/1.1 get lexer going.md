Get Lexer going
===============

Not working yet.
Get working.


```yaml
type: task
status: in progress
blocks: parser
priority: high
```


- [x] document-to-line splitter
- [x] reorganise test output folders
- [x] combine lexer items into one package
- [x] rename AST to TokenTree
- [x] rename .ast test output to .tt
- [x] add ability to test single file
- [X] recombine token nodes into single array
- [cancelled] add token nodes for things like colon, newline, start/end document
- [x] split doc on different newline types




Splitters
---------

Got the document-to-line splitter working last night.
I think anything that requires recombining lines can be done at later stages so this is no problem right now.
Not sure if I actually need to preserve the lineends in the AST - can do that if needed.

Indentation
-----------
Next I'll split lines into indentation and statements

All leading tabs are indentation, anything else becomes part of the statement.

Might need a way to indicate that a node terminates, ie that it has no children (a leaf).
The switch in the node lexer will fall through if it doesn't find a splitter, but might be nice to make it more explicit.

Setting a node type
-------------------

One possible option:
https://stackoverflow.com/questions/9993178/is-there-a-nice-way-to-simulate-a-maybe-or-option-type-in-go

This technique might be good for some cases, but it's probably not needed here yet.
See for example:
https://stackoverflow.com/questions/59964619/difference-using-pointer-in-struct-fields

There are a few caveats noted, so will just use another flag to indicate a terminal node for now.
Can change later if wanted.




AST node types - generic or specific?
-------------------------------------
At the moment I just have a single generic ASTNode that I was intending to return from each lexing phase, so I just end up with a tree of those.
Do I actually need different ast node structs for each node type, or is that getting ahead of things?
Is specific node types something i want to eject from parsing instead?


Update
------
I need to rename some things and set some guidelines.
Have been going back to some lexing/parsing articles and I need to rename the output of the lexer to something like 'TokenTree'.
The abstract syntax tree (AST) is supposed to be emitted by the parser afaict.

* No proper logic in the lexer - only regex, basic splitting
* Syntax errors will be the job of the parser

Also have gone back and revisited name-type-value to clarify some concepts.
Going forward will treat types and values as distinct entities.


Back to work on the Lexer
-------------------------


There are a few things I'd like to add/implement while I'm working through this:

* Add placeholder tokens for some basic things like colons (name seprator), newlines, quotes, document start/end
* See if the token child array can be recombined combined into a single array - of type/interface *not sure*. This will be needed to ensure the sequence is preserved.


Efficiency of regex for line splitting
--------------------------------------

It's probably not a big deal for small documents, but I think using ordinary string methods will likely be quicker.
I'm currently stuck on whether I have any need to capture the specifics of the newlines, or capture them at all.
Do I really need to denote the start/ends of lines, or is a complete line enough to imply them?
Same goes for document start & end.
I can sort of think of some circumstances where it *might* be handy to have the document boundaries indicated, but realistically those moments are a while away.
I should probably just move on.
It can probably be cheaply changed later if really needed.
And I can manually add start/end tokens if really needed.

I've changed the document splitter it now normalises newlines to `\n` first, then does an ordinary string split.


Split statements
----------------

Next step is to do the basic statement split

I also want to say at this point that I'm pretty unsatisfied with the lexer code so far.
It feels really awkward, like it could be simplified a whole lot.
I'll get thew next bit going first, then try to reevaluate.

Had a bit of a diversion into some unusual syntax options for colons, and trying to figure out how the stament structure works.
I'm kind of not sure I can do this *correctly* with just regex.
And if I allow for colon-as-placeholder, I have to allow for that.

These are the main statement options afaict:

	| (name): (entityExpression)
	| (:?)(entityExpression)
	| (name):
	| :





